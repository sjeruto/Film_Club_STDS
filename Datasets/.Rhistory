library(doParallel)
library(corrplot)
library(summarytools)
library(dplyr)
library(lubridate) # fixing the date
library(Hmisc) # describe()
library(funModeling) # profiling_num()
library(dlookr) # plot_normality(), normality()
library(dummies) # creating dummy variables
library(skimr) # skim()
library(tictoc)
library(StatMeasures)
library(cowplot)
library(lattice)
library(zoo)
library(DMwR)
library(pROC)
# Read in the model dataset
credfile=read.csv("AT2_credit_train.csv", fileEncoding = "UTF-8-BOM",
header=T, na.strings=c(""))
# Remove ID field as it will not add to the model
credfile2 <- credfile[ -c(1)]
# Remove SEX to remove gender bias from the model
credfile2$SEX <- NULL
# Remove dirty data
credfile2 <- filter(credfile2, LIMIT_BAL != -99)
# Convert education 6 to 5 & 0 to 5
credfile2$EDUCATION[credfile2$EDUCATION == 5] <- 4
credfile2$EDUCATION[credfile2$EDUCATION == 6] <- 4
credfile2$EDUCATION[credfile2$EDUCATION == 0] <- 4
# Change default column to numeric binary classification variables
credfile2$default[credfile2$default == "Y"] <- 1
credfile2$default[credfile2$default == "N"] <- 0
# Changing some variables into factor and some variables to numeric
credfile2[2:3] <- lapply(credfile2[2:3], as.factor)
credfile2[5:10] <- lapply(credfile2[5:10], as.factor)
credfile2$AGE<- as.numeric(credfile2$AGE)
credfile2$LIMIT_BAL <- as.numeric(credfile2$LIMIT_BAL)
credfile2[11:23] <- lapply(credfile2[11:23], as.numeric)
credfile2$default <- as.numeric(credfile2$default)
str(credfile2)
# Drop invalid columns for PAY_AMTN
credfile2[,17:22]<-NULL
str(credfile2)
# Defining the tuned hyperparameters
gbm_depth = 15 #maximum nodes per tree
gbm_n_min = 25 #minimum number of observations in the trees terminal
gbm_shrinkage = 0.001 #learning rate
cores_num = detectCores() - 1 #number of cores. Leave 1 for OS.
gbm_cv_folds = 10 #number of cross-validation folds to perform
num_trees = 15000 #number of iterations
## Run the GBM Model on the tuned hyperparameters
tic("GBM Model")
credfile_gbm = gbm(training$default~.,
data=training[, -ncol(training)],
distribution='bernoulli', # classification
n.trees=num_trees,
interaction.depth= gbm_depth,
n.minobsinnode = gbm_n_min,
shrinkage=gbm_shrinkage,
cv.folds=gbm_cv_folds,
verbose = TRUE, #print the preliminary output
n.cores = cores_num
)
toc()
# Make a test/train split
set.seed(267)
trainset_indices <- caret::createDataPartition(credfile2$default, p=0.75, list=F)
training <- credfile2[trainset_indices, ]
testset <- credfile2[-trainset_indices, ]
# Checks
nrow(training)
nrow(testset)
nrow(credfile2)
prop.table(table(training$default))
prop.table(table(testset$default))
prop.table(table(credfile2$default))
# Perform smote on training set
training$default <- as.factor(training$default)
training <- SMOTE(default ~ ., training, perc.over=100, perc.under=200)
training$default <- as.numeric(levels(training$default)[training$default])
prop.table(table(training$default))
str(training)
# Checks
nrow(training)
# Defining the tuned hyperparameters
gbm_depth = 15 #maximum nodes per tree
prop.table(table(training$default))
gbm_n_min = 25 #minimum number of observations in the trees terminal
gbm_shrinkage = 0.001 #learning rate
cores_num = detectCores() - 1 #number of cores. Leave 1 for OS.
gbm_cv_folds = 10 #number of cross-validation folds to perform
num_trees = 15000 #number of iterations
## Run the GBM Model on the tuned hyperparameters
tic("GBM Model")
credfile_gbm = gbm(training$default~.,
data=training[, -ncol(training)],
distribution='bernoulli', # classification
n.trees=num_trees,
interaction.depth= gbm_depth,
n.minobsinnode = gbm_n_min,
shrinkage=gbm_shrinkage,
cv.folds=gbm_cv_folds,
verbose = TRUE, #print the preliminary output
n.cores = cores_num
)
toc()
# Estimate the optimal number of iterations
best_iter = gbm.perf(credfile_gbm, method = "cv")
print(best_iter)
varImp(best_iter)
varImp(credfile_gbm)
credfile_gbm
1
2
plot(credfile_gbm)
# Variable importance
summary(credfile_gbm, n.trees=best_iter,
ylab = "Variable", main = "Variable Relative Importance")
# Use the model to predict probability of default
testset$probability = predict(credfile_gbm, testset,
n.trees = best_iter, type = "response")
testset$prediction = 0
# Convert probability >50% to prediction
testset[testset$probability >= 0.5, "prediction"] = 1
# Proportion of default
prop.table(table(testset$prediction))
# Confusion matrix
confusion_matrix <- table(pred=testset$prediction,true=testset$default)
confusion_matrix
library(dplyr)
library(tidyverse)
#avoids scientific notation on transaction IDs
options(scipen=999)
#import the files
file1 <- read.csv('~/R/STL-01.009 (2).csv', header=T, skip=3)
file2 <- read.csv('~/R/STL-01.009 (3).csv', header=T, skip=3)
file3 <- read.csv('~/R/STL-01.009 (4).csv', header=T, skip=3)
file4 <- read.csv('~/R/STL-01.009 (5).csv', header=T, skip=3)
file1$fileNum <- 'file01'
file2$fileNum <- 'file02'
file3$fileNum <- 'file03'
file4$fileNum <- 'file04'
#combined all the files
combined <- file1
combined <- rbind2(combined, file2)
combined <- rbind2(combined, file3)
combined <- rbind2(combined, file4)
#drop event codes T0400 which relates to the batch settlements
combined <- combined %>%
filter(Transaction.Event.Code != "T0400")
#drop the FX trailers (i.e. CH: FF, RC, RF, SC, SF)
combined <- combined %>%
filter(!CH %in% c("FF", "RC", "RF", "SC", "SF"))
#drop the blank PayPal reference IDs
#combined <- combined %>%
#  filter(!is.infinite(PayPal.Reference.ID) , PayPal.Reference.ID != "" , PayPal.Reference.ID != 0)
#covert NA to Zero
combined <- combined %>%
mutate(Fee.Amount = ifelse(is.na(Fee.Amount), 0, Fee.Amount)) %>%
mutate(Fee.Amount = ifelse(Fee.Amount == "", 0, Fee.Amount)) %>%
transform(Fee.Amount = as.numeric(Fee.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(is.na(Gross.Transaction.Amount), 0, Gross.Transaction.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(Gross.Transaction.Amount == "", 0, Gross.Transaction.Amount)) %>%
transform(Gross.Transaction.Amount = as.numeric(Gross.Transaction.Amount))
#covert amounts from cents to dollar values
combined <- combined %>%
mutate(Gross.Transaction.Amount = if_else(Transaction.Debit.or.Credit == "DR", (Gross.Transaction.Amount / 100 * -1) , Gross.Transaction.Amount / 100)) %>%
mutate(Fee.Amount = if_else(Fee.Debit.or.Credit == "DR", (Fee.Amount / 100 * - 1), Fee.Amount / 100))
#Create a daily settlement summary total to Rec to bank
bank_rec <- combined %>%
select(23, 10, 13)
bank_rec <- bank_rec %>%
mutate(Net = (as.numeric(Gross.Transaction.Amount) + as.numeric(Fee.Amount)))
bank_rec <- bank_rec %>%
select(1,4) %>%
group_by(fileNum) %>%
summarise_each(funs(sum))
write.csv(combined,'~/R/combined.csv', row.names = FALSE)
library(dplyr)
library(tidyverse)
#avoids scientific notation on transaction IDs
options(scipen=999)
#import the files
file1 <- read.csv('~/R/STL-01.009.csv', header=T, skip=3)
#drop event codes T0400 which relates to the batch settlements
combined <- combined %>%
filter(Transaction.Event.Code != "T0400")
#drop the FX trailers (i.e. CH: FF, RC, RF, SC, SF)
combined <- combined %>%
filter(!CH %in% c("FF", "RC", "RF", "SC", "SF"))
#covert NA to Zero
combined <- combined %>%
mutate(Fee.Amount = ifelse(is.na(Fee.Amount), 0, Fee.Amount)) %>%
mutate(Fee.Amount = ifelse(Fee.Amount == "", 0, Fee.Amount)) %>%
transform(Fee.Amount = as.numeric(Fee.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(is.na(Gross.Transaction.Amount), 0, Gross.Transaction.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(Gross.Transaction.Amount == "", 0, Gross.Transaction.Amount)) %>%
transform(Gross.Transaction.Amount = as.numeric(Gross.Transaction.Amount))
#drop the FX trailers (i.e. CH: FF, RC, RF, SC, SF)
combined <- combined %>%
filter(!CH %in% c("FF", "RC", "RF", "SC", "SF"))
#combined all the files
combined <- file1
#drop event codes T0400 which relates to the batch settlements
combined <- combined %>%
filter(Transaction.Event.Code != "T0400")
#drop the FX trailers (i.e. CH: FF, RC, RF, SC, SF)
combined <- combined %>%
filter(!CH %in% c("FF", "RC", "RF", "SC", "SF"))
#covert NA to Zero
combined <- combined %>%
mutate(Fee.Amount = ifelse(is.na(Fee.Amount), 0, Fee.Amount)) %>%
mutate(Fee.Amount = ifelse(Fee.Amount == "", 0, Fee.Amount)) %>%
transform(Fee.Amount = as.numeric(Fee.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(is.na(Gross.Transaction.Amount), 0, Gross.Transaction.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(Gross.Transaction.Amount == "", 0, Gross.Transaction.Amount)) %>%
transform(Gross.Transaction.Amount = as.numeric(Gross.Transaction.Amount))
#covert amounts from cents to dollar values
combined <- combined %>%
mutate(Gross.Transaction.Amount = if_else(Transaction.Debit.or.Credit == "DR", (Gross.Transaction.Amount / 100 * -1) , Gross.Transaction.Amount / 100)) %>%
mutate(Fee.Amount = if_else(Fee.Debit.or.Credit == "DR", (Fee.Amount / 100 * - 1), Fee.Amount / 100))
#Create a daily settlement summary total to Rec to bank
bank_rec <- combined %>%
select(23, 10, 13)
bank_rec <- bank_rec %>%
mutate(Net = (as.numeric(Gross.Transaction.Amount) + as.numeric(Fee.Amount)))
library(dplyr)
library(tidyverse)
#avoids scientific notation on transaction IDs
options(scipen=999)
#import the files
file1 <- read.csv('~/R/STL-01.009.csv', header=T, skip=3)
file2 <- read.csv('~/R/STL-01.009 (1).csv', header=T, skip=3)
file1$fileNum <- 'file01'
file2$fileNum <- 'file02'
#combined all the files
combined <- file1
combined <- rbind2(combined, file2)
#drop event codes T0400 which relates to the batch settlements
combined <- combined %>%
filter(Transaction.Event.Code != "T0400")
#drop the FX trailers (i.e. CH: FF, RC, RF, SC, SF)
combined <- combined %>%
filter(!CH %in% c("FF", "RC", "RF", "SC", "SF"))
#covert NA to Zero
combined <- combined %>%
mutate(Fee.Amount = ifelse(is.na(Fee.Amount), 0, Fee.Amount)) %>%
mutate(Fee.Amount = ifelse(Fee.Amount == "", 0, Fee.Amount)) %>%
transform(Fee.Amount = as.numeric(Fee.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(is.na(Gross.Transaction.Amount), 0, Gross.Transaction.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(Gross.Transaction.Amount == "", 0, Gross.Transaction.Amount)) %>%
transform(Gross.Transaction.Amount = as.numeric(Gross.Transaction.Amount))
#covert amounts from cents to dollar values
combined <- combined %>%
mutate(Gross.Transaction.Amount = if_else(Transaction.Debit.or.Credit == "DR", (Gross.Transaction.Amount / 100 * -1) , Gross.Transaction.Amount / 100)) %>%
mutate(Fee.Amount = if_else(Fee.Debit.or.Credit == "DR", (Fee.Amount / 100 * - 1), Fee.Amount / 100))
#Create a daily settlement summary total to Rec to bank
bank_rec <- combined %>%
select(23, 10, 13)
bank_rec <- bank_rec %>%
mutate(Net = (as.numeric(Gross.Transaction.Amount) + as.numeric(Fee.Amount)))
bank_rec <- bank_rec %>%
select(1,4) %>%
group_by(fileNum) %>%
summarise_each(funs(sum))
write.csv(combined,'~/R/combined.csv', row.names = FALSE)
library(dplyr)
library(tidyverse)
#avoids scientific notation on transaction IDs
options(scipen=999)
#import the files
file1 <- read.csv('~/R/STL-01.009.csv', header=T, skip=3)
file2 <- read.csv('~/R/STL-01.009 (1).csv', header=T, skip=3)
file1$fileNum <- 'file01'
file2$fileNum <- 'file02'
#combined all the files
combined <- file1
combined <- rbind2(combined, file2)
#drop event codes T0400 which relates to the batch settlements
combined <- combined %>%
filter(Transaction.Event.Code != "T0400")
#drop the FX trailers (i.e. CH: FF, RC, RF, SC, SF)
combined <- combined %>%
filter(!CH %in% c("FF", "RC", "RF", "SC", "SF"))
#covert NA to Zero
combined <- combined %>%
mutate(Fee.Amount = ifelse(is.na(Fee.Amount), 0, Fee.Amount)) %>%
mutate(Fee.Amount = ifelse(Fee.Amount == "", 0, Fee.Amount)) %>%
transform(Fee.Amount = as.numeric(Fee.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(is.na(Gross.Transaction.Amount), 0, Gross.Transaction.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(Gross.Transaction.Amount == "", 0, Gross.Transaction.Amount)) %>%
transform(Gross.Transaction.Amount = as.numeric(Gross.Transaction.Amount))
#covert amounts from cents to dollar values
combined <- combined %>%
mutate(Gross.Transaction.Amount = if_else(Transaction.Debit.or.Credit == "DR", (Gross.Transaction.Amount / 100 * -1) , Gross.Transaction.Amount / 100)) %>%
mutate(Fee.Amount = if_else(Fee.Debit.or.Credit == "DR", (Fee.Amount / 100 * - 1), Fee.Amount / 100))
#Create a daily settlement summary total to Rec to bank
bank_rec <- combined %>%
select(23, 10, 13)
bank_rec <- bank_rec %>%
mutate(Net = (as.numeric(Gross.Transaction.Amount) + as.numeric(Fee.Amount)))
bank_rec <- bank_rec %>%
select(1,4) %>%
group_by(fileNum) %>%
summarise_each(funs(sum))
write.csv(combined,'~/R/combined.csv', row.names = FALSE)
View(bank_rec)
data()
str(trees)
attach(mpg)
data()
attach(mpg)
head(displ)
library(mpg)
import.packages("mpg")
library(mpg)
library(tidyverse)
data()
mpg
attach(mpg)
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy, color = class)) +
scale_color_brewer(palette = "Set2") +
labs(title = "mpg Data")
str(mpg)
dim(mpg)
nrows(mpg)
nrow(mpg)
ncol(mpg)
length(mpg)
names(mpg)
correl(mpg)
#summary stats
summary(mpg)
#look at a sample of it
sample(mpg)
head(mpg)
tail(mpg)
#or for dataframes you can also find cols using
length(mpg$model)
cols(mpg)
col(mpg)
mpg[,0]
mpg[,1]
mpg[0,]
stat(mpg)
#look at a sample of it
sample(mpg)
#finding dimensions
dim(mpg)
library(hablar)
install.packages("hablar")
library(hablar)
head(table3)
table3 %>% separate(rate, c("cases", "population")) %>% convert(num(cases, population))
library(tidyverse)
library(skimr)
library(summarytools)
library(corrplot)
library(Hmisc)        # describe()
library(funModeling)  # profiling_num()
library(dlookr)       # plot_normality(), normality()
library(DataExplorer) # plot_str()
library(plotly)       # ggplotly(), plot_ly()
library(dummies)      # creating dummy variables
library(likert)
#import
combined <- read.csv('combined.csv')
setwd("~/GitHub/Film_Club_STDS/Datasets")
#import
combined <- read.csv('combined.csv')
tmdbdummy <- read.csv('tmdbdummy.csv')
tmdbdummy$X <- NULL
#load packages
library(tidyverse)
library(wbstats)
library(lubridate)
library(stringr)
require(likert)
data("pisaitems")
#import the tmdb files
file1 <- read.csv('tmdb clean 1-126118 range.csv')
file2 <- read.csv('tmdb clean 126119-199999 range.csv')
file3 <- read.csv('tmdb clean 200000-299999 range.csv')
file4 <- read.csv('tmdb clean 300000-371114 range.csv')
file5 <- read.csv('tmdb clean 371114-399999 range.csv')
file6 <- read.csv('tmdb clean 400000-499999 range.csv')
#merge files
combined <- rbind2(file1, file2)
combined <- rbind2(combined, file3)
combined <- rbind2(combined, file4)
combined <- rbind2(combined, file5)
combined <- rbind2(combined, file6)
#Code to get countries data
Country_Data <- select(wb_countries(),iso3c, country, income_level)
file8 <- read.csv('HOMOSEXUALITY.csv')
file9 <- read.csv('RELIGION_IMPORT.csv')
combined$release_date[combined$release_date == ""] <- NA
combined$year <- year(combined$release_date)
#select relevant data
tmdb <- tenyears %>%
select(production_countries.name
,original_language
,budget
,genres.name
,adult)
#pivot wider the survey responses
gender <- file7 %>%
select(country, GENDER_EQUALITY, weighted_n)
#import culture questions
file7 <- read.csv('GENDER_EQUALITY.csv')
#create dummy variable for year of release
combined$release_date <- lubridate::dmy(combined$release_date)
names(gender_pivot) <- c("country", "gender_VI", "gender_SI", "gender_NTI", "gender_NIAA", "gender_DK", "gender_R")
lgbtqi_pivot <- pivot_wider(lgbtqi
,id_cols = country
,names_from = HOMOSEXUALITY
,values_from = weighted_n)
#filter for last 10 years
tenyears <- combined %>%
filter(year > 2010)
#drop NA values
tmdb <- na.omit(tmdb)
gender_pivot <- pivot_wider(gender
,id_cols = country
,names_from = GENDER_EQUALITY
,values_from = weighted_n)
names(lgbtqi_pivot) <- c("country", "lgbtqi_Y", "lgbtqi_N", "lgbtqi_DK", "lgbtqi_R")
#pivot wider the survey responses
lgbtqi <- file8 %>%
select(country, HOMOSEXUALITY, weighted_n)
#pivot wider the survey responses
religion <- file9 %>%
select(country, RELIGION_IMPORT, weighted_n)
religion_pivot <- pivot_wider(religion
,id_cols = country
,names_from = RELIGION_IMPORT
,values_from = weighted_n)
names(religion_pivot) <- c("country", "religion_VI", "religion_SI", "religion_NTI", "religion_NIAA", "religion_DK", "religion_R")
#survey questions joined
survey_joined <- left_join(gender_pivot, lgbtqi_pivot, by= "country")
survey_joined <- left_join(survey_joined, religion_pivot, by= "country")
#convert country names to match for join
survey_joined$country <- str_replace(survey_joined$country, "United States", "United States of America")
clean_country <- data.frame(lapply(Country_Data, function(x) {
gsub("United States", "United States of America", x)
}))
clean_country <- data.frame(lapply(clean_country, function(x) {
gsub("Slovak Republic", "Slovakia", x)
}))
clean_country <- data.frame(lapply(clean_country, function(x) {
gsub("Korea, Rep.", "South Korea", x)
}))
clean_country <- data.frame(lapply(clean_country, function(x) {
gsub("Russian Federation", "Russia", x)
}))
#join country_data with tmdb
tmdbjoined <- left_join(tmdb, clean_country, by= c("production_countries.name" = "country"))
#join country_data with tmdb
tmdbjoined <- inner_join(tmdbjoined, survey_joined, by= c("production_countries.name" = "country"))
## write to csv
write.csv(tmdbjoined, "tmdbjoined.csv")
#create a dummy variable for
mature <- c("Action", "Crime", "Thriller", "Horror", "War")
tmdbdummy <- tmdbjoined %>%
mutate(mature = ifelse(genres.name %in% mature, 1, 0))
tmdbdummy$genres.name <- NULL
tmdbdummy$adult <- NULL
#combine "Don't Know" & "Refused" to answer for all culture questions
tmdbdummy$gender_Neut <- (tmdbdummy$gender_DK + tmdbdummy$gender_R)
tmdbdummy$lgbtqi_Neut <- (tmdbdummy$lgbtqi_DK + tmdbdummy$lgbtqi_R)
tmdbdummy$religion_Neut <- (tmdbdummy$religion_DK + tmdbdummy$religion_R)
tmdbdummy$gender_DK <- NULL
tmdbdummy$gender_R <- NULL
tmdbdummy$lgbtqi_DK <- NULL
tmdbdummy$lgbtqi_R <- NULL
tmdbdummy$religion_DK <- NULL
tmdbdummy$religion_R <- NULL
#combine "Very Important" & "Somewhat Important" to answer for all culture questions
tmdbdummy$gender_Y <- (tmdbdummy$gender_VI + tmdbdummy$gender_SI)
tmdbdummy$religion_Y <- (tmdbdummy$religion_VI + tmdbdummy$religion_SI)
tmdbdummy$gender_VI <- NULL
tmdbdummy$gender_SI <- NULL
tmdbdummy$religion_VI <- NULL
tmdbdummy$religion_SI <- NULL
#import
combined <- read.csv('combined.csv')
tmdbdummy <- read.csv('tmdbdummy.csv')
tmdbdummy$X <- NULL
#plot budget vs vote_avg.
ggplot(combined, aes(budget, vote_average, colour = genres.name)) +
geom_point() +
ggtitle("budget vs average vote")
#plot budget vs revenue
ggplot(combined, aes(budget, (budget-revenue), colour = genres.name)) +
geom_point()+
ggtitle("budget vs revenue")
#plot budget vs revenue
no_nas <- na.omit(combined)
View(no_nas)
no_nas <- no_nas %>%
filter(budget > 0 | revenue > 0)
ggplot(combined, aes(budget, (revenue-budget), colour = genres.name)) +
geom_point()+
ggtitle("budget vs revenue")
ggplot(no_nas, aes(budget, (revenue-budget), colour = genres.name)) +
geom_point()+
ggtitle("budget vs revenue")
ggplot(no_nas, aes(budget, (revenue-budget), colour = genres.name)) +
geom_point()+
ggtitle("budget vs profit")
