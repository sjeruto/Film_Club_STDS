gg_age <- gg_age %>%
filter(default == 1) %>%
select(AGE, LIMIT_BAL) %>%
group_by(AGE) %>%
summarise(mean(LIMIT_BAL))
names(gg_age)[2] <- "LIMIT_BAL"
p3<-gg_age %>% ggplot(aes(x=AGE, y=LIMIT_BAL)) +
geom_point()+
ggtitle("AVG CREDIT LIMIT BY AGE")+
coord_flip()+
theme_minimal()
p3
p3<-gg_age %>% ggplot(aes(x=AGE, y=LIMIT_BAL)) +
geom_point()+
ggtitle("AVERAGE CREDIT LIMIT BY AGE")+
coord_flip()+
theme_minimal()
p3
library(tidyverse)
library(ggplot2)
library(plotly)
library(caret)
library(DataExplorer)
library(glmnet)
library(pls)
library(rpart)
library(rpart.plot)
library(mlbench)
library(randomForest)
library(gbm)
library(parallel)
library(ROCR)
library(e1071)
library(pdp)
library(doParallel)
library(corrplot)
library(summarytools)
library(dplyr)
library(lubridate) # fixing the date
library(Hmisc) # describe()
library(funModeling) # profiling_num()
library(dlookr) # plot_normality(), normality()
library(dummies) # creating dummy variables
library(skimr) # skim()
library(tictoc)
library(StatMeasures)
library(cowplot)
library(lattice)
library(zoo)
library(DMwR)
library(pROC)
# Read in the model dataset
credfile=read.csv("AT2_credit_train.csv", fileEncoding = "UTF-8-BOM",
header=T, na.strings=c(""))
# Remove ID field as it will not add to the model
credfile2 <- credfile[ -c(1)]
# Remove SEX to remove gender bias from the model
credfile2$SEX <- NULL
# Remove dirty data
credfile2 <- filter(credfile2, LIMIT_BAL != -99)
# Convert education 6 to 5 & 0 to 5
credfile2$EDUCATION[credfile2$EDUCATION == 5] <- 4
credfile2$EDUCATION[credfile2$EDUCATION == 6] <- 4
credfile2$EDUCATION[credfile2$EDUCATION == 0] <- 4
# Change default column to numeric binary classification variables
credfile2$default[credfile2$default == "Y"] <- 1
credfile2$default[credfile2$default == "N"] <- 0
# Changing some variables into factor and some variables to numeric
credfile2[2:3] <- lapply(credfile2[2:3], as.factor)
credfile2[5:10] <- lapply(credfile2[5:10], as.factor)
credfile2$AGE<- as.numeric(credfile2$AGE)
credfile2$LIMIT_BAL <- as.numeric(credfile2$LIMIT_BAL)
credfile2[11:23] <- lapply(credfile2[11:23], as.numeric)
credfile2$default <- as.numeric(credfile2$default)
str(credfile2)
# Drop invalid columns for PAY_AMTN
credfile2[,17:22]<-NULL
str(credfile2)
# Defining the tuned hyperparameters
gbm_depth = 15 #maximum nodes per tree
gbm_n_min = 25 #minimum number of observations in the trees terminal
gbm_shrinkage = 0.001 #learning rate
cores_num = detectCores() - 1 #number of cores. Leave 1 for OS.
gbm_cv_folds = 10 #number of cross-validation folds to perform
num_trees = 15000 #number of iterations
## Run the GBM Model on the tuned hyperparameters
tic("GBM Model")
credfile_gbm = gbm(training$default~.,
data=training[, -ncol(training)],
distribution='bernoulli', # classification
n.trees=num_trees,
interaction.depth= gbm_depth,
n.minobsinnode = gbm_n_min,
shrinkage=gbm_shrinkage,
cv.folds=gbm_cv_folds,
verbose = TRUE, #print the preliminary output
n.cores = cores_num
)
toc()
# Make a test/train split
set.seed(267)
trainset_indices <- caret::createDataPartition(credfile2$default, p=0.75, list=F)
training <- credfile2[trainset_indices, ]
testset <- credfile2[-trainset_indices, ]
# Checks
nrow(training)
nrow(testset)
nrow(credfile2)
prop.table(table(training$default))
prop.table(table(testset$default))
prop.table(table(credfile2$default))
# Perform smote on training set
training$default <- as.factor(training$default)
training <- SMOTE(default ~ ., training, perc.over=100, perc.under=200)
training$default <- as.numeric(levels(training$default)[training$default])
prop.table(table(training$default))
str(training)
# Checks
nrow(training)
# Defining the tuned hyperparameters
gbm_depth = 15 #maximum nodes per tree
prop.table(table(training$default))
gbm_n_min = 25 #minimum number of observations in the trees terminal
gbm_shrinkage = 0.001 #learning rate
cores_num = detectCores() - 1 #number of cores. Leave 1 for OS.
gbm_cv_folds = 10 #number of cross-validation folds to perform
num_trees = 15000 #number of iterations
## Run the GBM Model on the tuned hyperparameters
tic("GBM Model")
credfile_gbm = gbm(training$default~.,
data=training[, -ncol(training)],
distribution='bernoulli', # classification
n.trees=num_trees,
interaction.depth= gbm_depth,
n.minobsinnode = gbm_n_min,
shrinkage=gbm_shrinkage,
cv.folds=gbm_cv_folds,
verbose = TRUE, #print the preliminary output
n.cores = cores_num
)
toc()
# Estimate the optimal number of iterations
best_iter = gbm.perf(credfile_gbm, method = "cv")
print(best_iter)
varImp(best_iter)
varImp(credfile_gbm)
credfile_gbm
1
2
plot(credfile_gbm)
# Variable importance
summary(credfile_gbm, n.trees=best_iter,
ylab = "Variable", main = "Variable Relative Importance")
# Use the model to predict probability of default
testset$probability = predict(credfile_gbm, testset,
n.trees = best_iter, type = "response")
testset$prediction = 0
# Convert probability >50% to prediction
testset[testset$probability >= 0.5, "prediction"] = 1
# Proportion of default
prop.table(table(testset$prediction))
# Confusion matrix
confusion_matrix <- table(pred=testset$prediction,true=testset$default)
confusion_matrix
library(dplyr)
library(tidyverse)
#avoids scientific notation on transaction IDs
options(scipen=999)
#import the files
file1 <- read.csv('~/R/STL-01.009 (2).csv', header=T, skip=3)
file2 <- read.csv('~/R/STL-01.009 (3).csv', header=T, skip=3)
file3 <- read.csv('~/R/STL-01.009 (4).csv', header=T, skip=3)
file4 <- read.csv('~/R/STL-01.009 (5).csv', header=T, skip=3)
file1$fileNum <- 'file01'
file2$fileNum <- 'file02'
file3$fileNum <- 'file03'
file4$fileNum <- 'file04'
#combined all the files
combined <- file1
combined <- rbind2(combined, file2)
combined <- rbind2(combined, file3)
combined <- rbind2(combined, file4)
#drop event codes T0400 which relates to the batch settlements
combined <- combined %>%
filter(Transaction.Event.Code != "T0400")
#drop the FX trailers (i.e. CH: FF, RC, RF, SC, SF)
combined <- combined %>%
filter(!CH %in% c("FF", "RC", "RF", "SC", "SF"))
#drop the blank PayPal reference IDs
#combined <- combined %>%
#  filter(!is.infinite(PayPal.Reference.ID) , PayPal.Reference.ID != "" , PayPal.Reference.ID != 0)
#covert NA to Zero
combined <- combined %>%
mutate(Fee.Amount = ifelse(is.na(Fee.Amount), 0, Fee.Amount)) %>%
mutate(Fee.Amount = ifelse(Fee.Amount == "", 0, Fee.Amount)) %>%
transform(Fee.Amount = as.numeric(Fee.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(is.na(Gross.Transaction.Amount), 0, Gross.Transaction.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(Gross.Transaction.Amount == "", 0, Gross.Transaction.Amount)) %>%
transform(Gross.Transaction.Amount = as.numeric(Gross.Transaction.Amount))
#covert amounts from cents to dollar values
combined <- combined %>%
mutate(Gross.Transaction.Amount = if_else(Transaction.Debit.or.Credit == "DR", (Gross.Transaction.Amount / 100 * -1) , Gross.Transaction.Amount / 100)) %>%
mutate(Fee.Amount = if_else(Fee.Debit.or.Credit == "DR", (Fee.Amount / 100 * - 1), Fee.Amount / 100))
#Create a daily settlement summary total to Rec to bank
bank_rec <- combined %>%
select(23, 10, 13)
bank_rec <- bank_rec %>%
mutate(Net = (as.numeric(Gross.Transaction.Amount) + as.numeric(Fee.Amount)))
bank_rec <- bank_rec %>%
select(1,4) %>%
group_by(fileNum) %>%
summarise_each(funs(sum))
write.csv(combined,'~/R/combined.csv', row.names = FALSE)
library(dplyr)
library(tidyverse)
#avoids scientific notation on transaction IDs
options(scipen=999)
#import the files
file1 <- read.csv('~/R/STL-01.009.csv', header=T, skip=3)
#drop event codes T0400 which relates to the batch settlements
combined <- combined %>%
filter(Transaction.Event.Code != "T0400")
#drop the FX trailers (i.e. CH: FF, RC, RF, SC, SF)
combined <- combined %>%
filter(!CH %in% c("FF", "RC", "RF", "SC", "SF"))
#covert NA to Zero
combined <- combined %>%
mutate(Fee.Amount = ifelse(is.na(Fee.Amount), 0, Fee.Amount)) %>%
mutate(Fee.Amount = ifelse(Fee.Amount == "", 0, Fee.Amount)) %>%
transform(Fee.Amount = as.numeric(Fee.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(is.na(Gross.Transaction.Amount), 0, Gross.Transaction.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(Gross.Transaction.Amount == "", 0, Gross.Transaction.Amount)) %>%
transform(Gross.Transaction.Amount = as.numeric(Gross.Transaction.Amount))
#drop the FX trailers (i.e. CH: FF, RC, RF, SC, SF)
combined <- combined %>%
filter(!CH %in% c("FF", "RC", "RF", "SC", "SF"))
#combined all the files
combined <- file1
#drop event codes T0400 which relates to the batch settlements
combined <- combined %>%
filter(Transaction.Event.Code != "T0400")
#drop the FX trailers (i.e. CH: FF, RC, RF, SC, SF)
combined <- combined %>%
filter(!CH %in% c("FF", "RC", "RF", "SC", "SF"))
#covert NA to Zero
combined <- combined %>%
mutate(Fee.Amount = ifelse(is.na(Fee.Amount), 0, Fee.Amount)) %>%
mutate(Fee.Amount = ifelse(Fee.Amount == "", 0, Fee.Amount)) %>%
transform(Fee.Amount = as.numeric(Fee.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(is.na(Gross.Transaction.Amount), 0, Gross.Transaction.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(Gross.Transaction.Amount == "", 0, Gross.Transaction.Amount)) %>%
transform(Gross.Transaction.Amount = as.numeric(Gross.Transaction.Amount))
#covert amounts from cents to dollar values
combined <- combined %>%
mutate(Gross.Transaction.Amount = if_else(Transaction.Debit.or.Credit == "DR", (Gross.Transaction.Amount / 100 * -1) , Gross.Transaction.Amount / 100)) %>%
mutate(Fee.Amount = if_else(Fee.Debit.or.Credit == "DR", (Fee.Amount / 100 * - 1), Fee.Amount / 100))
#Create a daily settlement summary total to Rec to bank
bank_rec <- combined %>%
select(23, 10, 13)
bank_rec <- bank_rec %>%
mutate(Net = (as.numeric(Gross.Transaction.Amount) + as.numeric(Fee.Amount)))
library(dplyr)
library(tidyverse)
#avoids scientific notation on transaction IDs
options(scipen=999)
#import the files
file1 <- read.csv('~/R/STL-01.009.csv', header=T, skip=3)
file2 <- read.csv('~/R/STL-01.009 (1).csv', header=T, skip=3)
file1$fileNum <- 'file01'
file2$fileNum <- 'file02'
#combined all the files
combined <- file1
combined <- rbind2(combined, file2)
#drop event codes T0400 which relates to the batch settlements
combined <- combined %>%
filter(Transaction.Event.Code != "T0400")
#drop the FX trailers (i.e. CH: FF, RC, RF, SC, SF)
combined <- combined %>%
filter(!CH %in% c("FF", "RC", "RF", "SC", "SF"))
#covert NA to Zero
combined <- combined %>%
mutate(Fee.Amount = ifelse(is.na(Fee.Amount), 0, Fee.Amount)) %>%
mutate(Fee.Amount = ifelse(Fee.Amount == "", 0, Fee.Amount)) %>%
transform(Fee.Amount = as.numeric(Fee.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(is.na(Gross.Transaction.Amount), 0, Gross.Transaction.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(Gross.Transaction.Amount == "", 0, Gross.Transaction.Amount)) %>%
transform(Gross.Transaction.Amount = as.numeric(Gross.Transaction.Amount))
#covert amounts from cents to dollar values
combined <- combined %>%
mutate(Gross.Transaction.Amount = if_else(Transaction.Debit.or.Credit == "DR", (Gross.Transaction.Amount / 100 * -1) , Gross.Transaction.Amount / 100)) %>%
mutate(Fee.Amount = if_else(Fee.Debit.or.Credit == "DR", (Fee.Amount / 100 * - 1), Fee.Amount / 100))
#Create a daily settlement summary total to Rec to bank
bank_rec <- combined %>%
select(23, 10, 13)
bank_rec <- bank_rec %>%
mutate(Net = (as.numeric(Gross.Transaction.Amount) + as.numeric(Fee.Amount)))
bank_rec <- bank_rec %>%
select(1,4) %>%
group_by(fileNum) %>%
summarise_each(funs(sum))
write.csv(combined,'~/R/combined.csv', row.names = FALSE)
library(dplyr)
library(tidyverse)
#avoids scientific notation on transaction IDs
options(scipen=999)
#import the files
file1 <- read.csv('~/R/STL-01.009.csv', header=T, skip=3)
file2 <- read.csv('~/R/STL-01.009 (1).csv', header=T, skip=3)
file1$fileNum <- 'file01'
file2$fileNum <- 'file02'
#combined all the files
combined <- file1
combined <- rbind2(combined, file2)
#drop event codes T0400 which relates to the batch settlements
combined <- combined %>%
filter(Transaction.Event.Code != "T0400")
#drop the FX trailers (i.e. CH: FF, RC, RF, SC, SF)
combined <- combined %>%
filter(!CH %in% c("FF", "RC", "RF", "SC", "SF"))
#covert NA to Zero
combined <- combined %>%
mutate(Fee.Amount = ifelse(is.na(Fee.Amount), 0, Fee.Amount)) %>%
mutate(Fee.Amount = ifelse(Fee.Amount == "", 0, Fee.Amount)) %>%
transform(Fee.Amount = as.numeric(Fee.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(is.na(Gross.Transaction.Amount), 0, Gross.Transaction.Amount)) %>%
mutate(Gross.Transaction.Amount = ifelse(Gross.Transaction.Amount == "", 0, Gross.Transaction.Amount)) %>%
transform(Gross.Transaction.Amount = as.numeric(Gross.Transaction.Amount))
#covert amounts from cents to dollar values
combined <- combined %>%
mutate(Gross.Transaction.Amount = if_else(Transaction.Debit.or.Credit == "DR", (Gross.Transaction.Amount / 100 * -1) , Gross.Transaction.Amount / 100)) %>%
mutate(Fee.Amount = if_else(Fee.Debit.or.Credit == "DR", (Fee.Amount / 100 * - 1), Fee.Amount / 100))
#Create a daily settlement summary total to Rec to bank
bank_rec <- combined %>%
select(23, 10, 13)
bank_rec <- bank_rec %>%
mutate(Net = (as.numeric(Gross.Transaction.Amount) + as.numeric(Fee.Amount)))
bank_rec <- bank_rec %>%
select(1,4) %>%
group_by(fileNum) %>%
summarise_each(funs(sum))
write.csv(combined,'~/R/combined.csv', row.names = FALSE)
View(bank_rec)
data()
str(trees)
attach(mpg)
data()
attach(mpg)
head(displ)
library(mpg)
import.packages("mpg")
library(mpg)
library(tidyverse)
data()
mpg
attach(mpg)
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy, color = class)) +
scale_color_brewer(palette = "Set2") +
labs(title = "mpg Data")
str(mpg)
dim(mpg)
nrows(mpg)
nrow(mpg)
ncol(mpg)
length(mpg)
names(mpg)
correl(mpg)
#summary stats
summary(mpg)
#look at a sample of it
sample(mpg)
head(mpg)
tail(mpg)
#or for dataframes you can also find cols using
length(mpg$model)
cols(mpg)
col(mpg)
mpg[,0]
mpg[,1]
mpg[0,]
stat(mpg)
#look at a sample of it
sample(mpg)
#finding dimensions
dim(mpg)
library(hablar)
install.packages("hablar")
library(hablar)
head(table3)
table3 %>% separate(rate, c("cases", "population")) %>% convert(num(cases, population))
setwd("~/GitHub/Film_Club_STDS/Datasets")
#import the files
file1 <- read.csv('tmdb clean 1-126118 range.csv')
file2 <- read.csv('tmdb clean 126119-199999 range.csv')
file4 <- read.csv('tmdb clean 300000-371114 range.csv')
file5 <- read.csv('tmdb clean 371115-399999 range.csv')
file5 <- read.csv('tmdb clean 371114-399999 range.csv')
file5 <- read.csv('tmdb clean 371114-399999 range.csv')
file6 <- read.csv('tmdb clean 400000-499999 range.csv')
#merge files
combined <- rbind2(file1, file2)
combined <- rbind2(combined, file3)
combined <- rbind2(combined, file4)
combined <- rbind2(combined, file5)
combined <- rbind2(combined, file6)
## country ratio
country <- combined %>%
select(production_countries.name, genres.name, original_title) %>%
group_by(production_countries.name, genres.name) %>%
summarise(n = n())
## country ratio
df$release_date[df$release_date == ""] <- NA
## country ratio
df$release_date[df$release_date == ""] <- NA
View(combined)
## country ratio
country <- combined %>%
select(production_countries.name, genres.name, original_title) %>%
group_by(production_countries.name, genres.name) %>%
summarise(n = n())
#load packages
library(tidyverse)
library(gtools)
library(lubridate)
## country ratio
country <- combined %>%
select(production_countries.name, genres.name, original_title) %>%
group_by(production_countries.name, genres.name) %>%
summarise(n = n())
## country ratio
combined$release_date[df$release_date == ""] <- NA
View(combined)
## country ratio
combined$release_date[df$release_date == ""] <- NA
## country ratio
as.Date(combined, "%m/%d/%Y")
## country ratio
as.Date(combined$release_date, "%m/%d/%Y")
combined$release_date[df$release_date == ""] <- NA
## country ratio
combined$release_date <- as.Date(combined$release_date, "%m/%d/%Y")
combined$release_date[df$release_date == ""] <- NA
#merge files
combined <- rbind2(file1, file2)
combined <- rbind2(combined, file3)
combined <- rbind2(combined, file4)
combined <- rbind2(combined, file5)
combined <- rbind2(combined, file6)
## country ratio
country <- combined %>%
select(production_countries.name, genres.name, original_title) %>%
group_by(production_countries.name, genres.name) %>%
summarise(n = n())
View(country)
## country ratio
combined$release_date <- lubridate::dmy(combined$release_date)
combined$release_date[df$release_date == ""] <- NA
combined$release_date[df$release_date == ""] <- NA
combined$release_date[combined$release_date == ""] <- NA
combined$year <- year(combined$release_date)
country <- df %>%
filter(year > 2010)
country <- combined %>%
filter(year > 2010)
country <- country %>%
select(production_countries.name, genres.name, original_title) %>%
group_by(production_countries.name, genres.name) %>%
summarise(n = n())
country_pivot <- pivot_wider(country
,id_cols = production_countries.name
,names_from = genres.name
,values_from = n)
country_pivot$total <- rowSums(country_pivot[,-1], na.rm=TRUE)
country_pivot <- pivot_longer(country_pivot,
cols = -c(production_countries.name|total),
names_to = "genre",
values_to = "value")
country_pivot$total[is.na(country_pivot$total)] <- 0
country_pivot$value[is.na(country_pivot$value)] <- 0
country_pivot <- country_pivot %>% filter(total > 50)
country_pivot$perc <- round((country_pivot$value /country_pivot$total * 100), 2)
country_pivot <- country_pivot %>%
select(production_countries.name, genre, perc)
country_pivot <- pivot_wider(country_pivot
,id_cols = production_countries.name
,names_from = genre
,values_from = perc)
View(country_pivot)
##OECD Data
gdp <-
readSDMX( providerId= "OECD",
resource ="data",
flowRef = "SNA_TABLE1",
key = "/",
key.mode = "SDMX",
dsd = T) #This is where we say we want the data dictionary
library(rsmdx)
install.packages("rsmdx")
library(rsmdx)
library(rsdmx)
##OECD Data
income <-
readSDMX( providerId= "OECD",
resource ="data",
flowRef = "IDD",
key = "/",
key.mode = "SDMX",
dsd = F) #This is where we say we want the data dictionary
View(income)
#puts XML in dataframe.
incomeid <-as.data.frame(income, labels = F)
View(incomeid)
